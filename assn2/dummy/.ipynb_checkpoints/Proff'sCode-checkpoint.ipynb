{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "given-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/rnar/.local/lib/python3.9/site-packages (1.24.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hybrid-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fit( words, verbose = False ):\n",
    "    dt = Tree( min_leaf_size = 1, max_depth = 15 )\n",
    "    dt.fit( words, verbose )\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "veterinary-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__( self, min_leaf_size, max_depth ):\n",
    "        self.root = None\n",
    "        self.words = None\n",
    "        self.min_leaf_size = min_leaf_size\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit( self, words, verbose = False ):\n",
    "        self.words = words\n",
    "        self.root = Node( depth = 0, parent = None )\n",
    "        # The root is trained with all the words\n",
    "        self.root.fit(all_words = self.words, \n",
    "                      my_words_idx = np.arange( len( self.words ) ), \n",
    "                      min_leaf_size = self.min_leaf_size, \n",
    "                      max_depth = self.max_depth, \n",
    "                      verbose = verbose )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welcome-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    # A node stores its own depth (root = depth 0), a link to its parent\n",
    "    # A link to all the words as well as the words that reached that node\n",
    "    # A dictionary is used to store the children of a non-leaf node.\n",
    "    # Each child is paired with the response that selects that child.\n",
    "    # A node also stores the query-response history that led to that node\n",
    "    # Note: my_words_idx only stores indices and not the words themselves\n",
    "    def __init__(self, depth, parent ):\n",
    "        self.depth = depth\n",
    "        self.parent = parent\n",
    "        self.all_words = None\n",
    "        self.my_words_idx = None\n",
    "        self.children = {}\n",
    "        self.is_leaf = True\n",
    "        self.query_idx = None\n",
    "        self.history = []\n",
    "    \n",
    "    # Each node must implement a get_query method that generates the\n",
    "    # query that gets asked when we reach that node. Note that leaf nodes\n",
    "    # also generate a query which is usually the final answer\n",
    "    def get_query( self ):\n",
    "        return self.query_idx\n",
    "    \n",
    "    # Each non-leaf node must implement a get_child method that takes a\n",
    "    # response and selects one of the children based on that response\n",
    "    def get_child( self, response ):\n",
    "        # This case should not arise if things are working properly\n",
    "        # Cannot return a child if I am a leaf so return myself as a default action\n",
    "        if self.is_leaf:\n",
    "            print( \"Why is a leaf node being asked to produce a child? Melbot should look into this!!\" )\n",
    "            child = self\n",
    "        else:\n",
    "            # This should ideally not happen. The node should ensure that all possibilities\n",
    "            # are covered, e.g. by having a catch-all response. Fix the model if this happens\n",
    "            # For now, hack things by modifying the response to one that exists in the dictionary\n",
    "            if response not in self.children:\n",
    "                print( f\"Unknown response {response} -- need to fix the model\" )\n",
    "                response = list(self.children.keys())[0]\n",
    "            \n",
    "            child = self.children[ response ]\n",
    "            \n",
    "        return child\n",
    "    \n",
    "    # Dummy leaf action -- just return the first word\n",
    "    def process_leaf(self, \n",
    "                     my_words_idx, \n",
    "                     history ):\n",
    "        return my_words_idx[0]\n",
    "    \n",
    "    def reveal(self, \n",
    "               word, \n",
    "               query ):\n",
    "        # Find out the intersections between the query and the word\n",
    "        mask = [ *( '_' * len( word ) ) ]\n",
    "        \n",
    "        for i in range( min( len( word ), len( query ) ) ):\n",
    "            if word[i] == query[i]:\n",
    "                mask[i] = word[i]\n",
    "        \n",
    "        return ' '.join( mask )\n",
    "    \n",
    "    # Dummy node splitting action -- use a random word as query\n",
    "    # Note that any word in the dictionary can be the query\n",
    "    def process_node(self, \n",
    "                     all_words, \n",
    "                     my_words_idx, \n",
    "                     history, \n",
    "                     verbose ):\n",
    "        # For the root we do not ask any query -- Melbot simply gives us the length of the secret word\n",
    "        if len( history ) == 0:\n",
    "            query_idx = -1\n",
    "            query = \"\"\n",
    "        else:\n",
    "            query_idx = np.random.randint( 0, len( all_words ) )\n",
    "            query = all_words[ query_idx ]\n",
    "        \n",
    "        split_dict = {}\n",
    "        \n",
    "        for idx in my_words_idx:\n",
    "            mask = self.reveal( all_words[ idx ], query )\n",
    "            if mask not in split_dict:\n",
    "                split_dict[ mask ] = []\n",
    "            \n",
    "            split_dict[ mask ].append( idx )\n",
    "        \n",
    "        if len( split_dict.items() ) < 2 and verbose:\n",
    "            print( \"Warning: did not make any meaningful split with this query!\" )\n",
    "        \n",
    "        return ( query_idx, split_dict )\n",
    "    \n",
    "    def fit(self, \n",
    "            all_words, \n",
    "            my_words_idx, \n",
    "            min_leaf_size, \n",
    "            max_depth, \n",
    "            fmt_str = \"    \", \n",
    "            verbose = False ):\n",
    "        self.all_words = all_words\n",
    "        self.my_words_idx = my_words_idx\n",
    "        \n",
    "        # If the node is too small or too deep, make it a leaf\n",
    "        # In general, can also include purity considerations into account\n",
    "        if len( my_words_idx ) <= min_leaf_size or self.depth >= max_deph:\n",
    "            self.is_leaf = True\n",
    "            self.query_idx = self.process_leaf(self.my_words_idx, \n",
    "                                               self.history )\n",
    "        else:\n",
    "            self.is_leaf = False\n",
    "            ( self.query_idx, split_dict ) = self.process_node(self.all_words, \n",
    "                                                               self.my_words_idx, \n",
    "                                                               self.history, verbose )\n",
    "            \n",
    "            for ( i, ( response, split ) ) in enumerate( split_dict.items() ):\n",
    "                \n",
    "                # Create a new child for every split\n",
    "                self.children[ response ] = Node( depth = self.depth + 1, parent = self )\n",
    "                history = self.history.copy()\n",
    "                history.append( [ self.query_idx, response ] )\n",
    "                self.children[ response ].history = history\n",
    "                \n",
    "                # Recursively train this child node\n",
    "                self.children[ response ].fit(self.all_words, \n",
    "                                              split, \n",
    "                                              min_leaf_size, \n",
    "                                              max_depth, \n",
    "                                              fmt_str, verbose )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-financing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
